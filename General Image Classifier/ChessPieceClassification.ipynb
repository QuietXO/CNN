{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# **_Chess Piece Classification_**\n",
    "\n",
    "### __*This CNN is supposed to determine what kind of Chess Piece is in the Image*__"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<br>\n",
    "\n",
    "### __*Import Libraries and choose the device*__"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Import of the Libraries\n",
    "import os\n",
    "import CNN\n",
    "\n",
    "# Torch libraries\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Device config (Pick your set-up)\n",
    "# GPU = torch.device('cpu')  # CPU\n",
    "GPU = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  # NVIDIA GPUs\n",
    "# GPU = torch.device('mps' if torch.has_mps else 'cpu')  # ARM GPUs (M1, M2, ...)\n",
    "print('Using the Processor') if GPU == torch.device('cpu') else print('Using the Graphics Card')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<br>\n",
    "\n",
    "### __*Training Preparation (Set all variables here)*__"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Hyper-parameters\n",
    "num_epochs = 25         # How many times to repeat learning\n",
    "batch_size = 8          # Number of images to send at once\n",
    "learning_rate = 0.001    # How quickly should it learn\n",
    "\n",
    "# Image Dimensions\n",
    "IMG_SIZE = 85           # 85*85 pixels\n",
    "COLOUR_SIZE = 1\n",
    "\n",
    "# Define the directory\n",
    "FILE_PATH = './data/chess/pieces'           # Sub-Folders Location\n",
    "CSV_PATH = './data/chess/data.csv'          # CSV Location\n",
    "TRAIN_CSV = './data/chess/train_data.csv'   # Train CSV Location\n",
    "TEST_CSV = './data/chess/test_data.csv'     # Test CSV Location\n",
    "CATEGORIES = os.listdir(FILE_PATH)          # Turn Sub-Folder names into a list\n",
    "N_CLASSES = len(CATEGORIES)                 # Number of different classes\n",
    "\n",
    "# TODO: Create a normalization function with advanced formula\n",
    "# Transformation\n",
    "transformer = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.RandomVerticalFlip(),\n",
    "    torchvision.transforms.Grayscale()\n",
    "])\n",
    "\n",
    "# Create the .csv file & dictionary\n",
    "CNN.data.create_csv(FILE_PATH, CSV_PATH, rewrite=True)\n",
    "\n",
    "# Create the Datasets\n",
    "dataset = CNN.data.CustomDataset(FILE_PATH, CSV_PATH, transform=transformer)\n",
    "\n",
    "# Get Normalizer\n",
    "normal_loader = DataLoader(dataset=dataset, batch_size=len(dataset))\n",
    "data = next(iter(normal_loader))\n",
    "MEAN = data[0].mean()\n",
    "STD = data[0].std()\n",
    "\n",
    "# Normalized Transformation\n",
    "trans_normal = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.RandomVerticalFlip(),\n",
    "    torchvision.transforms.Grayscale(),\n",
    "    torchvision.transforms.Normalize(MEAN, STD)\n",
    "])\n",
    "\n",
    "# Create the .csv file & dictionary\n",
    "indexing = CNN.data.create_csv(FILE_PATH, train_csv=TRAIN_CSV, test_csv=TEST_CSV,\n",
    "                      rewrite=True, split=True, test_ratio=0.2, mul=2)\n",
    "\n",
    "# Create the Datasets\n",
    "train_dataset = CNN.data.CustomDataset(FILE_PATH, TRAIN_CSV, transform=trans_normal)\n",
    "test_dataset = CNN.data.CustomDataset(FILE_PATH, TEST_CSV, transform=trans_normal)\n",
    "\n",
    "# Create the DataLoaders\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size)\n",
    "\n",
    "# Create the Model\n",
    "model = CNN.model.ConvNet(COLOUR_SIZE, N_CLASSES).to(GPU)\n",
    "\n",
    "# Choose type of Loss & Optimization function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### __*Look at some data*__"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get dataset overview\n",
    "CNN.visual.overview(train_dataset, test_dataset, indexing)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<br>\n",
    "\n",
    "### __*Training Loop*__"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Train the Model\n",
    "CNN.model.train_model(model, train_loader, criterion, optimizer, num_epochs, device=GPU)\n",
    "\n",
    "# Save the Model\n",
    "SAVE_PATH = './chess.pth'\n",
    "torch.save(model.state_dict(), SAVE_PATH)\n",
    "\n",
    "# Test the Model\n",
    "res = CNN.model.load_model(model, test_loader, CATEGORIES, show_wrongs=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
