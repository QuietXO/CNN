{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# **_Chess Piece Detection_**\n",
    "\n",
    "### __*This CNN is supposed to determine what kind of Chess Piece is in the Image*__"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<br>\n",
    "\n",
    "### __*Import Libraries and choose the device*__"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the Graphics Card\n"
     ]
    }
   ],
   "source": [
    "# Import of the Libraries\n",
    "import os\n",
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Torch libraries\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Device config (Pick your set-up)\n",
    "GPU = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  # NVIDIA GPUs\n",
    "# GPU = torch.device('mps' if torch.has_mps else 'cpu')  # ARM GPUs (M1, M2, ...)\n",
    "print('Using the Processor') if GPU == torch.device('cpu') else print('Using the Graphics Card')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<br>\n",
    "\n",
    "### __*Convert the Images into a Dataset format for PyTorch*__"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Define the directory\n",
    "FILE_PATH = './data/chess'          # Sub-Folders Location\n",
    "CATEGORIES = os.listdir(FILE_PATH)  # Turn Sub-Folder names into a list\n",
    "\n",
    "# Image Size\n",
    "IMG_SIZE = 85  # All images should be 85*85 anyway\n",
    "\n",
    "\n",
    "# Convert the Images into a Training & Test Dataset\n",
    "def create_dataset(file_path, categories, test_ratio=0.2, dtype=np.float32):\n",
    "    dataset = []\n",
    "    # Fill the dataset with arrays of img info + label\n",
    "    for category in categories:\n",
    "        path = os.path.join(file_path, category)\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
    "                img_array_resized = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "                img_tensor = torch.from_numpy(np.array(img_array_resized).astype(dtype))\n",
    "                dataset.append([img_tensor, category])\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "    # Split the dataset into a train & test datasets\n",
    "    train_data, test_data = train_test_split(dataset, test_size=test_ratio)\n",
    "\n",
    "    # Turn the datasets into Tensors\n",
    "    # train_data = torch.from_numpy(np.array(train_data).astype(dtype))\n",
    "    # test_data = torch.from_numpy(np.array(test_data).astype(dtype))\n",
    "\n",
    "    return train_data, test_data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### __*Visual representation of the dataset*__"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[ 93., 167., 160.,  ..., 165., 159., 155.],\n",
      "        [ 93., 167., 162.,  ..., 172., 172., 163.],\n",
      "        [ 93., 167., 161.,  ..., 163., 171., 169.],\n",
      "        ...,\n",
      "        [111., 169., 188.,  ..., 200., 201., 198.],\n",
      "        [144., 163., 172.,  ..., 181., 182., 182.],\n",
      "        [170., 171., 122.,  ..., 115., 118., 118.]]), 'pawn']\n",
      "<class 'list'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'str'>\n",
      "413\n",
      "104\n",
      "[('bishop', 54), ('king', 22), ('knight', 55), ('pawn', 200), ('queen', 24), ('rook', 58)]\n",
      "[('bishop', 13), ('king', 12), ('knight', 16), ('pawn', 39), ('queen', 10), ('rook', 14)]\n"
     ]
    }
   ],
   "source": [
    "print_train, print_test = create_dataset(FILE_PATH, CATEGORIES)\n",
    "\n",
    "\n",
    "#print_test = torch.from_numpy(print_test[0][0])\n",
    "print(print_test[0])\n",
    "print(type(print_test[0]))\n",
    "print(type(print_test[0][0]))\n",
    "print(type(print_test[0][1]))\n",
    "\n",
    "\n",
    "\n",
    "print(len(print_train))\n",
    "print(len(print_test))\n",
    "\n",
    "train_dct = dict()\n",
    "for item in print_train:\n",
    "    try:\n",
    "        train_dct[item[1]] += 1\n",
    "    except KeyError:\n",
    "        train_dct[item[1]] = 1\n",
    "print(sorted(train_dct.items()))\n",
    "\n",
    "test_dct = dict()\n",
    "for item in print_test:\n",
    "    try:\n",
    "        test_dct[item[1]] += 1\n",
    "    except KeyError:\n",
    "        test_dct[item[1]] = 1\n",
    "print(sorted(test_dct.items()))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### __*Training Loop*__"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Hyper-parameters\n",
    "num_epochs = 15\n",
    "batch_size = 8\n",
    "learning_rate = 0.001"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
